{"cells":[{"cell_type":"code","source":["## Get the current size of the DW - the size of all the active tables\n","# (This does not match what you get from Azure Storage Explorer)\n","\n","from notebookutils import mssparkutils\n","\n","def scan_folder(folder,total_size):\n","    #print(f\" folder = {folder}\")\n","    l0 = notebookutils.fs.ls(folder)\n","    for l1 in l0:\n","        if l1.isDir==False:\n","             #print(f\" name = {l1.name} : {l1.size/ 1024/1024:.2f} MB\")\n","             #print(f\" name = {l1.name} : {l1.size/1024:.2f} \")\n","             total_size = total_size + l1.size\n","    \n","    for l1 in l0:    \n","        if l1.isDir:\n","            dirsize = scan_folder(l1.path,  0);\n","            #print(f\"{l1.path} : {dirsize/1024:.2f}\")\n","            total_size = total_size + dirsize\n"," \n","    return total_size\n","\n","total_size=0.00;\n","\n","\n","# Workspace\n","delta_table_path = \"abfss://[workspace guid]@msit-onelake.dfs.fabric.microsoft.com/[warehouse guid]/Tables/\"\n","\n","total_size = scan_folder(delta_table_path, total_size)\n","total_size = total_size/ 1024/1024\n","print(f\"  Total Workspace Size: {total_size:.2f} MB\")"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"b0d7243d-bda3-4ec1-8f33-8d807dc5f8c1"},{"cell_type":"code","source":["## Get the current size of the total DW - including deleted data/tables\n","# (This does  match what you get from Azure Storage Explorer)\n","\n","from notebookutils import mssparkutils\n","\n","def scan_folder_logs(folder,total_size):\n","    #print(f\" folder = {folder}\")\n","    l0 = notebookutils.fs.ls(folder)\n","    for l1 in l0:\n","        if l1.isDir==False:\n","             #print(f\" name = {l1.name} : {l1.size/ 1024/1024:.2f} MB\")\n","             if(l1.name.find(\"json\") >0):\n","                #print(f\" name = {l1.name} : {l1.size/1024:.2f} \")\n","                total_size = total_size + l1.size\n","    \n","    for l1 in l0:    \n","        if l1.isDir:\n","            dirsize = scan_folder_logs(l1.path,  0);\n","            #print(f\"{l1.path} : {dirsize/1024:.2f}\")\n","            total_size = total_size + dirsize\n"," \n","    return total_size\n","\n","\n","def scan_folder_data(folder,total_size):\n","    #print(f\" folder = {folder}\")\n","    l0 = notebookutils.fs.ls(folder)\n","    for l1 in l0:\n","        if l1.isDir==False:\n","             #print(f\" name = {l1.name} : {l1.size/ 1024/1024:.2f} MB\")\n","             if(l1.name.find(\".parquet\") > 0):\n","                #print(f\" name = {l1.name} : {l1.size/1024:.2f} \")\n","                total_size = total_size + l1.size\n","    \n","    for l1 in l0:    \n","        if l1.isDir:\n","            dirsize = scan_folder_data(l1.path,  0);\n","            #print(f\"{l1.path} : {dirsize/1024:.2f}\")\n","            total_size = total_size + dirsize\n"," \n","    return total_size\n","\n","\n","total_size_logs=0.00;\n","\n","\n","# Workspace\n","delta_table_path = \"abfss://[workspace guid]@msit-onelake.dfs.fabric.microsoft.com/[warehouse guid]/Tables/\"\n","\n","total_size_logs = scan_folder_logs(delta_table_path, total_size_logs)\n","print(f\"  Total Logs: {total_size_logs:.2f} kb\")\n","total_size_logs = total_size_logs/ 1024/1024\n","print(f\"  Total Logs: {total_size_logs:.2f} MB\")\n","\n","\n","delta_table_path = \"abfss://[workspace guid]@msit-onelake.dfs.fabric.microsoft.com/[warehouse guid]/Files/\"\n","total_size_data=0.00;\n","total_size_data = scan_folder_data(delta_table_path, total_size_data)\n","print(f\"  Total Data: {total_size_data:.2f} kb\")\n","total_size_data = total_size_data/ 1024/1024\n","print(f\"  Total Data: {total_size_data:.2f} MB\")\n","\n","total = total_size_logs + total_size_data;\n","print(f\"  Everything : {total:.2f} MB\")"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"9deb8206-efde-459a-9c5c-90933993d5cf"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"synapse_widget":{"version":"0.1","state":{}},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"default_lakehouse":"6d2a102f-6dcd-4a81-b2ee-149f4228bf13","default_lakehouse_name":"rleenabled","default_lakehouse_workspace_id":"69220cac-c19c-4673-8294-1e181b2ff1cf"},"warehouse":{"known_warehouses":[{"id":"87e4b7a6-1f39-4681-92bb-3595a5f22c0e","type":"Datawarehouse"}],"default_warehouse":"87e4b7a6-1f39-4681-92bb-3595a5f22c0e"}}},"nbformat":4,"nbformat_minor":5}