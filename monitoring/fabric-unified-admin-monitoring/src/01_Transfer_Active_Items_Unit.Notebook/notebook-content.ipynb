{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "cceec85a-5432-4959-a940-51d7b49c0df9",
            "metadata": {},
            "source": [
                "#### Active items\n",
                "\n",
                "##### Data ingestion strategy:\n",
                "<mark style=\"background: #D69AFE;\">**MERGE**</mark>\n",
                "\n",
                "##### Related pipeline:\n",
                "\n",
                "**Load_Items_E2E**\n",
                "\n",
                "##### Source:\n",
                "\n",
                "**Files** from FUAM_Lakehouse folder **bronze_file_location** variable\n",
                "\n",
                "##### Target:\n",
                "\n",
                "**1 Delta table** in FUAM_Lakehouse \n",
                "- **gold_table_name** variable value"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "8e0dfb76-d449-4c62-b4ee-a55850f6f1b6",
            "metadata": {
                "cellStatus": "{\"System Administrator\":{\"session_start_time\":\"2025-02-13T23:17:22.9981662Z\",\"execution_start_time\":\"2025-02-13T23:17:50.7072828Z\",\"execution_finish_time\":\"2025-02-13T23:17:53.0498851Z\",\"state\":\"finished\",\"livy_statement_state\":\"available\",\"normalized_state\":\"finished\"}}",
                "microsoft": {
                    "language": "python",
                    "language_group": "synapse_pyspark"
                }
            },
            "outputs": [],
            "source": [
                "from pyspark.sql.functions import col, explode, to_date, date_format, lit\n",
                "from pyspark.sql import Window\n",
                "import pyspark.sql.functions as f\n",
                "from delta.tables import *\n",
                "import datetime\n",
                "spark.conf.set(\"spark.databricks.delta.schema.autoMerge.enabled\",\"true\") # needed for automatic schema evolution in merge "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "b5eb77a7-0eaa-4e0a-81c7-37d488a4b31c",
            "metadata": {
                "cellStatus": "{\"System Administrator\":{\"session_start_time\":null,\"execution_start_time\":\"2025-02-13T23:18:49.6665088Z\",\"execution_finish_time\":\"2025-02-13T23:18:49.9073189Z\",\"state\":\"finished\",\"livy_statement_state\":\"available\",\"normalized_state\":\"finished\"}}",
                "microsoft": {
                    "language": "python",
                    "language_group": "synapse_pyspark"
                },
                "tags": [
                    "parameters"
                ]
            },
            "outputs": [],
            "source": [
                "## Parameters\n",
                "display_data = False"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "519f57fd-0fdb-4646-8fa9-aac66087fe04",
            "metadata": {
                "cellStatus": "{\"System Administrator\":{\"session_start_time\":null,\"execution_start_time\":\"2025-02-13T23:17:53.6134723Z\",\"execution_finish_time\":\"2025-02-13T23:17:53.9068664Z\",\"state\":\"finished\",\"livy_statement_state\":\"available\",\"normalized_state\":\"finished\"}}",
                "microsoft": {
                    "language": "python",
                    "language_group": "synapse_pyspark"
                }
            },
            "outputs": [],
            "source": [
                "## Variables\n",
                "bronze_file_location = f\"Files/raw/active_items/\"\n",
                "silver_table_name = \"FUAM_Staging_Lakehouse.active_items_silver\"\n",
                "gold_table_name = \"active_items\"\n",
                "gold_table_name_with_prefix = f\"Tables/{gold_table_name}\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "d96bad65-f3c4-46fe-a54a-67ac04a67c80",
            "metadata": {
                "cellStatus": "{\"System Administrator\":{\"session_start_time\":null,\"execution_start_time\":\"2025-02-13T23:17:54.0319879Z\",\"execution_finish_time\":\"2025-02-13T23:18:16.2451303Z\",\"state\":\"finished\",\"livy_statement_state\":\"available\",\"normalized_state\":\"finished\"}}",
                "microsoft": {
                    "language": "python",
                    "language_group": "synapse_pyspark"
                }
            },
            "outputs": [],
            "source": [
                "# Clean Silver table, if exists\n",
                "if spark.catalog.tableExists(silver_table_name):\n",
                "    del_query = \"DELETE FROM \" + silver_table_name\n",
                "    spark.sql(del_query)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "ee9ec13d-3175-4e00-a736-d5f889752e92",
            "metadata": {
                "cellStatus": "{\"System Administrator\":{\"session_start_time\":null,\"execution_start_time\":\"2025-02-13T23:18:16.3746489Z\",\"execution_finish_time\":\"2025-02-13T23:18:16.6081509Z\",\"state\":\"finished\",\"livy_statement_state\":\"available\",\"normalized_state\":\"finished\"}}",
                "microsoft": {
                    "language": "python",
                    "language_group": "synapse_pyspark"
                }
            },
            "outputs": [],
            "source": [
                "# This function converts all complex data types to StringType\n",
                "def convert_columns_to_string(schema, parent = \"\", lvl = 0):\n",
                "    \"\"\"\n",
                "    Input:\n",
                "    - schema: Dataframe schema as StructType\n",
                "    \n",
                "    Output: List\n",
                "    Returns a list of columns in the schema casting them to String to use in a selectExpr Spark function.\n",
                "    \"\"\"\n",
                "    \n",
                "    lst=[]\n",
                "    \n",
                "    for x in schema:\n",
                "        # check if complex datatype has to be converted to string\n",
                "        if str(x.dataType) in {\"DateType()\", \"StringType()\", \"BooleanType()\", \"LongType()\", \"IntegerType()\", \"DoubleType()\", \"FloatType()\"}:\n",
                "            # no need to convert\n",
                "            lst.append(\"{col}\".format(col=x.name))\n",
                "        else:\n",
                "            # it has to be converted\n",
                "            # print(str(x.dataType))\n",
                "            lst.append(\"cast({col} as string) as {col}\".format(col=x.name))\n",
                "\n",
                "    return lst"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "14cc398a-d46f-4fa7-88c8-56dc243cf9b0",
            "metadata": {
                "cellStatus": "{\"System Administrator\":{\"session_start_time\":null,\"execution_start_time\":\"2025-02-13T23:18:16.7649728Z\",\"execution_finish_time\":\"2025-02-13T23:18:17.6150091Z\",\"state\":\"finished\",\"livy_statement_state\":\"available\",\"normalized_state\":\"finished\"}}",
                "microsoft": {
                    "language": "python",
                    "language_group": "synapse_pyspark"
                }
            },
            "outputs": [],
            "source": [
                "# Get Bronze data\n",
                "bronze_df = spark.read.option(\"multiline\", \"true\").json(bronze_file_location)\n",
                "\n",
                "if display_data:\n",
                "    display(bronze_df)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f8d02ab2-19a5-4877-9ffe-454cdc95c802",
            "metadata": {
                "cellStatus": "{\"System Administrator\":{\"session_start_time\":null,\"execution_start_time\":\"2025-02-13T23:20:02.3110793Z\",\"execution_finish_time\":\"2025-02-13T23:20:04.8540757Z\",\"state\":\"finished\",\"livy_statement_state\":\"available\",\"normalized_state\":\"finished\"}}",
                "collapsed": false,
                "microsoft": {
                    "language": "python",
                    "language_group": "synapse_pyspark"
                }
            },
            "outputs": [],
            "source": [
                "# Explode json subset structure\n",
                "exploded_df = bronze_df.select(explode(\"itemEntities\").alias(\"d\"))\n",
                "\n",
                "# Select all columns (columns are dynamic)\n",
                "silver_df = exploded_df.select(\n",
                "    col(\"d.*\")\n",
                "    )\n",
                "\n",
                "# Convert key(s) to upper case\n",
                "silver_df = silver_df.withColumn(\"id\", f.upper(f.col(\"id\")))\n",
                "silver_df = silver_df.withColumn(\"capacityId\", f.upper(f.col(\"capacityId\")))\n",
                "silver_df = silver_df.withColumn(\"workspaceId\", f.upper(f.col(\"workspaceId\")))\n",
                "\n",
                "# Added column creatorUserPrincipalName to enable easier identification of creator\n",
                "silver_df = silver_df.withColumn(\"creatorUserPrincipalName\", f.col(\"creatorPrincipal.userDetails.userPrincipalName\"))\n",
                "\n",
                "# Drop duplicates (API returns sometimes duplicated values)\n",
                "silver_df = silver_df.dropDuplicates()\n",
                "\n",
                "if display_data:\n",
                "    display(silver_df)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "1fd36928-cd34-4ff7-a631-9caaaa12f0f1",
            "metadata": {
                "cellStatus": "{\"System Administrator\":{\"session_start_time\":null,\"execution_start_time\":\"2025-02-13T23:21:08.2970077Z\",\"execution_finish_time\":\"2025-02-13T23:21:08.5326358Z\",\"state\":\"finished\",\"livy_statement_state\":\"available\",\"normalized_state\":\"finished\"}}",
                "microsoft": {
                    "language": "python",
                    "language_group": "synapse_pyspark"
                }
            },
            "outputs": [],
            "source": [
                "# show converted table schema\n",
                "if display_data:\n",
                "    convert_columns_to_string(silver_df.schema)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f47e952e-8b76-4e7a-86fb-9edacb0d6fe9",
            "metadata": {
                "cellStatus": "{\"System Administrator\":{\"session_start_time\":null,\"execution_start_time\":\"2025-02-13T23:21:11.284505Z\",\"execution_finish_time\":\"2025-02-13T23:21:11.5230202Z\",\"state\":\"finished\",\"livy_statement_state\":\"available\",\"normalized_state\":\"finished\"}}",
                "microsoft": {
                    "language": "python",
                    "language_group": "synapse_pyspark"
                }
            },
            "outputs": [],
            "source": [
                "# Convert silver_df's complex data type columns to StringType columns\n",
                "silver_df_converted = silver_df.selectExpr(convert_columns_to_string(silver_df.schema))         "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "080d2187-e9be-4675-931f-04ee2f29bcd5",
            "metadata": {
                "cellStatus": "{\"System Administrator\":{\"session_start_time\":null,\"execution_start_time\":\"2025-02-13T23:21:13.7739396Z\",\"execution_finish_time\":\"2025-02-13T23:21:23.8198386Z\",\"state\":\"finished\",\"livy_statement_state\":\"available\",\"normalized_state\":\"finished\"}}",
                "collapsed": false,
                "microsoft": {
                    "language": "python",
                    "language_group": "synapse_pyspark"
                }
            },
            "outputs": [],
            "source": [
                "# Write prepared bronze_df to silver delta table\n",
                "silver_df.write.mode(\"overwrite\").option(\"mergeSchema\", \"true\").format(\"delta\").saveAsTable(silver_table_name)\n",
                "\n",
                "if display_data:\n",
                "    display(silver_df)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "9aad5193-a856-49cc-a86f-9a03b71661a6",
            "metadata": {
                "cellStatus": "{\"System Administrator\":{\"session_start_time\":null,\"execution_start_time\":\"2025-02-13T23:21:23.9623238Z\",\"execution_finish_time\":\"2025-02-13T23:21:24.2561053Z\",\"state\":\"finished\",\"livy_statement_state\":\"available\",\"normalized_state\":\"finished\"}}",
                "jupyter": {
                    "outputs_hidden": false,
                    "source_hidden": false
                },
                "microsoft": {
                    "language": "python",
                    "language_group": "synapse_pyspark"
                },
                "nteract": {
                    "transient": {
                        "deleting": false
                    }
                }
            },
            "outputs": [],
            "source": [
                "\n",
                "# This function maps and merges the silver data to gold dynamically\n",
                "def write_silver_to_gold(silver_table_name, gold_table_name, ids):\n",
                "    query = \"SELECT *, current_timestamp() AS fuam_modified_at, False as fuam_deleted  FROM \" + \\\n",
                "        silver_table_name\n",
                "    silver_df = spark.sql(query)\n",
                "    windowspec = Window.partitionBy(\"id\").orderBy(f.desc(\"lastUpdatedDate\"))\n",
                "    silver_df = silver_df.withColumn(\"row_num\", f.row_number().over(\n",
                "        windowspec)).filter(f.col(\"row_num\") == 1).drop(\"row_num\")\n",
                "\n",
                "    if spark._jsparkSession.catalog().tableExists('FUAM_Lakehouse', gold_table_name):\n",
                "        # if exists -> MERGE to gold\n",
                "        print(\"Gold table exists and will be merged.\")\n",
                "        gold_df = DeltaTable.forName(spark, gold_table_name)\n",
                "\n",
                "        gold_columns = gold_df.toDF().columns\n",
                "        silver_columns = silver_df.columns\n",
                "        combined_columns = list(set(gold_columns) | set(silver_columns))\n",
                "        id_cols = {}\n",
                "        merge_id_stmt = ''\n",
                "        for col in combined_columns:\n",
                "            if col in ids:\n",
                "                merge_id_stmt = merge_id_stmt + \" t.\" + col + \" = s.\" + col + \" and\"\n",
                "                id_cols[col] = \"s.\" + col\n",
                "\n",
                "        # delete last and in merge id statement\n",
                "        merge_id_stmt = merge_id_stmt[:-4]\n",
                "\n",
                "        # Merge silver (s = source) to gold (t = target)\n",
                "        try:\n",
                "            merge = (gold_df.alias('t')\n",
                "                     .merge(silver_df.alias('s'), merge_id_stmt)) \\\n",
                "                .whenMatchedUpdateAll() \\\n",
                "                .whenNotMatchedInsertAll() \\\n",
                "                .whenNotMatchedBySourceUpdate(condition=\"t.fuam_deleted == False or t.fuam_deleted IS NULL\", set={\"fuam_deleted\": \"True\", \"fuam_modified_at\": \"current_timestamp()\"})\n",
                "\n",
                "            merge.execute()\n",
                "        except:\n",
                "            # In case the tables already exist, but the fuam column are not existent because of an old version do merge whenNotMatchedBySourceUpdate\n",
                "            merge = (gold_df.alias('t')\n",
                "                     .merge(silver_df.alias('s'), merge_id_stmt)) \\\n",
                "                .whenMatchedUpdateAll() \\\n",
                "                .whenNotMatchedInsertAll() \\\n",
                "\n",
                "            merge.execute()\n",
                "\n",
                "    else:\n",
                "        # else -> INSERT to gold\n",
                "        print(\"Gold table will be created.\")\n",
                "\n",
                "        silver_df.write.mode(\"append\").option(\"mergeSchema\", \"true\").format(\n",
                "            \"delta\").saveAsTable(gold_table_name)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "e3b04945-1480-4a12-be03-29a69237a7a9",
            "metadata": {
                "cellStatus": "{\"System Administrator\":{\"session_start_time\":null,\"execution_start_time\":\"2025-02-13T23:21:24.4192948Z\",\"execution_finish_time\":\"2025-02-13T23:21:34.6466747Z\",\"state\":\"finished\",\"livy_statement_state\":\"available\",\"normalized_state\":\"finished\"}}",
                "microsoft": {
                    "language": "python",
                    "language_group": "synapse_pyspark"
                }
            },
            "outputs": [],
            "source": [
                "# Merge data to gold table\n",
                "write_silver_to_gold(silver_table_name, gold_table_name, ['id'])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "7edc7384-0392-489b-853a-d1b75a74794d",
            "metadata": {
                "cellStatus": "{\"System Administrator\":{\"session_start_time\":null,\"execution_start_time\":\"2025-02-13T23:21:34.7864858Z\",\"execution_finish_time\":\"2025-02-13T23:21:35.584817Z\",\"state\":\"finished\",\"livy_statement_state\":\"available\",\"normalized_state\":\"finished\"}}",
                "microsoft": {
                    "language": "python",
                    "language_group": "synapse_pyspark"
                }
            },
            "outputs": [],
            "source": [
                "# write history of bronze files\n",
                "\n",
                "mssparkutils.fs.cp(bronze_file_location, bronze_file_location.replace(\"Files/raw/\", \"Files/history/\") + datetime.datetime.now().strftime('%Y/%m/%d') + \"/\", True)"
            ]
        }
    ],
    "metadata": {
        "a365ComputeOptions": null,
        "dependencies": {
            "environment": {},
            "lakehouse": {
                "default_lakehouse": "729eb8a2-8070-5ed8-ad43-dccbc00b32af",
                "default_lakehouse_name": "FUAM_Lakehouse",
                "default_lakehouse_workspace_id": "eb764c8b-cf3b-55be-adf4-348fe9233657",
                "known_lakehouses": []
            }
        },
        "kernel_info": {
            "name": "synapse_pyspark"
        },
        "kernelspec": {
            "display_name": "base",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.3"
        },
        "microsoft": {
            "language": "python",
            "language_group": "synapse_pyspark",
            "ms_spell_check": {
                "ms_spell_check_language": "en"
            }
        },
        "nteract": {
            "version": "nteract-front-end@1.0.0"
        },
        "sessionKeepAliveTimeout": 0,
        "spark_compute": {
            "compute_id": "/trident/default",
            "session_options": {
                "conf": {
                    "spark.synapse.nbs.session.timeout": "1200000"
                }
            }
        },
        "synapse_widget": {
            "state": {},
            "version": "0.1"
        },
        "widgets": {}
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
